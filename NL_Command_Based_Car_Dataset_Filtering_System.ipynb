{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOigNVMaBJ40UFypIUl+oBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah-shamito/LLMs-projects/blob/main/NL_Command_Based_Car_Dataset_Filtering_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "In this notebook, I will demonstrate the power of integrating LangChain with language models to create a robust system capable of interpreting natural language commands to filter and retrieve data from a CSV file.\n",
        "\n",
        "\n",
        "My system consists of several key components:\n",
        "1.\tData Parsing and Storage: I will load the dataset, which includes various attributes of cars, into a structured format that facilitates easy querying.\n",
        "2.\tCommand Interpretation: Utilizing LangChain integrated with OpenAI's model, I will develop an agent capable of parsing natural language. This agent identifies the intent of user commands and extracts relevant filtering criteria such as car make, model, color, etc.\n",
        "3.\tFiltering Logic: Based on the interpreted commands, the agent applies filtering logic to the dataset. This logic is designed to match the extracted criteria against the dataset to find and retrieve the relevant records.\n",
        "4.\tUser Interaction and Output: The results are then formatted and presented to the user in an easily understandable form.\n",
        "\n",
        "\n",
        "Note : While LangChain offers a streamlined approach to building this system, it's important to note that other NLP techniques can also be utilized to achieve similar results. Tools and frameworks such as spaCy, TensorFlow, and PyTorch offer powerful capabilities for building custom NLP solutions. In subsequent sections of this notebook, I will provide sample cells demonstrating how these technologies can be employed to build similar systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "UU9TJ0H2Fxmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R0N1KE6i6Gl",
        "outputId": "4be97aa8-4da5-4968-c38a-92140e1abb89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.59-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community<0.3,>=0.2 (from langchain_experimental)\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.3,>=0.2->langchain_experimental)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.1.65)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (8.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (2.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langchain_experimental) (2.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community<0.3,>=0.2->langchain_experimental) (0.2.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3,>=0.2->langchain_experimental) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3,>=0.2->langchain_experimental) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community, langchain_experimental\n",
            "Successfully installed dataclasses-json-0.6.6 langchain-community-0.2.1 langchain_experimental-0.0.59 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "#!pip install pandas tensorflow torch torchvision\n",
        "#!pip install transformers\n",
        "\n",
        "!pip -q install langchain openai\n",
        "!pip install langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "API_KEY = getpass.getpass(\"Enter your API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCbSLf6oCQxX",
        "outputId": "65fde60a-f549-49bb-ab1f-aa4428baa94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba0J_pZ1leaQ",
        "outputId": "eadb438b-cf7e-472a-897c-c9f52f8689b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.2.1\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: langchain-community\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Parsing and Storage"
      ],
      "metadata": {
        "id": "KYGJV1G4DqwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the dataset\n",
        "url = '/content/sample_data/cars.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "tleECdggjg1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bd982119-b603-4cb4-bff4-7e4dea2f21cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id Car Brand     Car Model Car Color  Year of Manufacture\n",
              "0  1.0      Ford    Club Wagon      Teal               1993.0\n",
              "1  2.0  Cadillac  Escalade ESV    Fuscia               2007.0\n",
              "2  3.0     Mazda    Miata MX-5    Orange               2009.0\n",
              "3  4.0      Audi            A4    Orange               2005.0\n",
              "4  5.0    Nissan        Maxima      Pink               1994.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d0d0e8c-5620-4592-86a9-e55f5d8b0164\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Car Brand</th>\n",
              "      <th>Car Model</th>\n",
              "      <th>Car Color</th>\n",
              "      <th>Year of Manufacture</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Ford</td>\n",
              "      <td>Club Wagon</td>\n",
              "      <td>Teal</td>\n",
              "      <td>1993.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Cadillac</td>\n",
              "      <td>Escalade ESV</td>\n",
              "      <td>Fuscia</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Mazda</td>\n",
              "      <td>Miata MX-5</td>\n",
              "      <td>Orange</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Audi</td>\n",
              "      <td>A4</td>\n",
              "      <td>Orange</td>\n",
              "      <td>2005.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Nissan</td>\n",
              "      <td>Maxima</td>\n",
              "      <td>Pink</td>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d0d0e8c-5620-4592-86a9-e55f5d8b0164')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d0d0e8c-5620-4592-86a9-e55f5d8b0164 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d0d0e8c-5620-4592-86a9-e55f5d8b0164');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e39db68-e8ce-468b-af94-18ff11b1ea39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e39db68-e8ce-468b-af94-18ff11b1ea39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e39db68-e8ce-468b-af94-18ff11b1ea39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29927,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886.607004772212,\n        \"min\": 1.0,\n        \"max\": 9999.0,\n        \"num_unique_values\": 9999,\n        \"samples\": [\n          5345.0,\n          7445.0,\n          1732.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Car Brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 77,\n        \"samples\": [\n          \"Nissan\",\n          \"Acura\",\n          \"Dodge\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Car Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 958,\n        \"samples\": [\n          \"Hearse\",\n          \"I\",\n          \"B-Series\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Car Color\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Teal\",\n          \"Khaki\",\n          \"Crimson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year of Manufacture\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.184016278272637,\n        \"min\": 1948.0,\n        \"max\": 2013.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          1982.0,\n          1983.0,\n          1993.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization of LangChain CSV Agent for Command Interpretation and Data Filtering"
      ],
      "metadata": {
        "id": "2p_amGzxE720"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents import create_csv_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "LuLIqOQalYew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_csv_agent(OpenAI(temperature=0),\n",
        "                         '/content/sample_data/cars.csv',\n",
        "                         verbose=True)"
      ],
      "metadata": {
        "id": "WKz86nCYm1Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdujJ0HSnCJg",
        "outputId": "199d492a-b6f6-4678-af25-f493abd4a703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
              "})\n",
              "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'df_head': '|    |   id | Car Brand   | Car Model    | Car Color   |   Year of Manufacture |\\n|---:|-----:|:------------|:-------------|:------------|----------------------:|\\n|  0 |    1 | Ford        | Club Wagon   | Teal        |                  1993 |\\n|  1 |    2 | Cadillac    | Escalade ESV | Fuscia      |                  2007 |\\n|  2 |    3 | Mazda       | Miata MX-5   | Orange      |                  2009 |\\n|  3 |    4 | Audi        | A4           | Orange      |                  2005 |\\n|  4 |    5 | Nissan      | Maxima       | Pink        |                  1994 |', 'tools': 'python_repl_ast - A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.', 'tool_names': 'python_repl_ast'}, template='\\nYou are working with a pandas dataframe in Python. The name of the dataframe is `df`.\\nYou should use the tools below to answer the question posed of you:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\n\\nThis is the result of `print(df.head())`:\\n{df_head}\\n\\nBegin!\\nQuestion: {input}\\n{agent_scratchpad}')\n",
              "| RunnableBinding(bound=OpenAI(client=<openai.resources.completions.Completions object at 0x7b571df5ea70>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7b571de28880>, temperature=0.0, openai_api_key='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', openai_proxy=''), kwargs={'stop': ['\\nObservation']})\n",
              "| ReActSingleInputOutputParser(), input_keys_arg=['input'], return_keys_arg=['output'], stream_runnable=True), tools=[PythonAstREPLTool(locals={'df':         id Car Brand     Car Model Car Color  Year of Manufacture\n",
              "0      1.0      Ford    Club Wagon      Teal               1993.0\n",
              "1      2.0  Cadillac  Escalade ESV    Fuscia               2007.0\n",
              "2      3.0     Mazda    Miata MX-5    Orange               2009.0\n",
              "3      4.0      Audi            A4    Orange               2005.0\n",
              "4      5.0    Nissan        Maxima      Pink               1994.0\n",
              "...    ...       ...           ...       ...                  ...\n",
              "29922  NaN       NaN           NaN       NaN                  NaN\n",
              "29923  NaN       NaN           NaN       NaN                  NaN\n",
              "29924  NaN       NaN           NaN       NaN                  NaN\n",
              "29925  NaN       NaN           NaN       NaN                  NaN\n",
              "29926  NaN       NaN           NaN       NaN                  NaN\n",
              "\n",
              "[29927 rows x 5 columns]})])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Zd-4m7bFA0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "h0nwK_UZFGAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Get me all Audi cars with color red\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "NYHNVDXTnG42",
        "outputId": "5759200e-2a2b-4f51-e20e-a0833f1b624a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe by car brand and car color\n",
            "Action: python_repl_ast\n",
            "Action Input: df[(df['Car Brand'] == 'Audi') & (df['Car Color'] == 'Red')]\u001b[0m\u001b[36;1m\u001b[1;3m          id Car Brand Car Model Car Color  Year of Manufacture\n",
            "2277  2278.0      Audi    riolet       Red               1995.0\n",
            "2683  2684.0      Audi        A5       Red               2012.0\n",
            "3236  3237.0      Audi        S4       Red               2001.0\n",
            "4203  4204.0      Audi        TT       Red               2008.0\n",
            "5453  5454.0      Audi    riolet       Red               1997.0\n",
            "5733  5734.0      Audi        S6       Red               1995.0\n",
            "6003  6004.0      Audi        A6       Red               1996.0\n",
            "6550  6551.0      Audi        Q7       Red               2011.0\n",
            "8338  8339.0      Audi        TT       Red               2003.0\n",
            "9486  9487.0      Audi        TT       Red               2000.0\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: df[(df['Car Brand'] == 'Audi') & (df['Car Color'] == 'Red')]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"df[(df['Car Brand'] == 'Audi') & (df['Car Color'] == 'Red')]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Get all Nissan Altima\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "qfnhFKk-nclb",
        "outputId": "c5f03835-98a0-4ed6-9641-c5bdd678bffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe for rows where the Car Brand is Nissan and the Car Model is Altima\n",
            "Action: python_repl_ast\n",
            "Action Input: df[(df['Car Brand'] == 'Nissan') & (df['Car Model'] == 'Altima')]\u001b[0m\u001b[36;1m\u001b[1;3m          id Car Brand Car Model   Car Color  Year of Manufacture\n",
            "36      37.0    Nissan    Altima      Orange               2002.0\n",
            "475    476.0    Nissan    Altima      Orange               2000.0\n",
            "512    513.0    Nissan    Altima  Aquamarine               2011.0\n",
            "864    865.0    Nissan    Altima      Indigo               2009.0\n",
            "889    890.0    Nissan    Altima      Orange               1995.0\n",
            "1397  1398.0    Nissan    Altima      Fuscia               2006.0\n",
            "1689  1690.0    Nissan    Altima     Crimson               1997.0\n",
            "2047  2048.0    Nissan    Altima      Indigo               2012.0\n",
            "2757  2758.0    Nissan    Altima      Violet               2013.0\n",
            "2968  2969.0    Nissan    Altima      Yellow               2008.0\n",
            "2991  2992.0    Nissan    Altima      Yellow               1997.0\n",
            "3089  3090.0    Nissan    Altima      Purple               2004.0\n",
            "3638  3639.0    Nissan    Altima      Yellow               2008.0\n",
            "3752  3753.0    Nissan    Altima      Maroon               2001.0\n",
            "4205  4206.0    Nissan    Altima     Crimson               1998.0\n",
            "4206  4207.0    Nissan    Altima         Red               2005.0\n",
            "4863  4864.0    Nissan    Altima        Pink               2008.0\n",
            "5261  5262.0    Nissan    Altima   Turquoise               2008.0\n",
            "5512  5513.0    Nissan    Altima      Violet               2007.0\n",
            "7495  7496.0    Nissan    Altima        Teal               2009.0\n",
            "7807  7808.0    Nissan    Altima        Blue               1993.0\n",
            "7912  7913.0    Nissan    Altima      Purple               2007.0\n",
            "8075  8076.0    Nissan    Altima  Aquamarine               2000.0\n",
            "8440  8441.0    Nissan    Altima      Maroon               2013.0\n",
            "8583  8584.0    Nissan    Altima      Yellow               2012.0\n",
            "8625  8626.0    Nissan    Altima       Green               2011.0\n",
            "8786  8787.0    Nissan    Altima      Yellow               2011.0\n",
            "9358  9359.0    Nissan    Altima       Khaki               2009.0\n",
            "9939  9940.0    Nissan    Altima       Green               1995.0\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: df[(df['Car Brand'] == 'Nissan') & (df['Car Model'] == 'Altima')]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"df[(df['Car Brand'] == 'Nissan') & (df['Car Model'] == 'Altima')]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"get all cars that were manufactured between 2000 and 2006\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "pmWYpgfFn0fn",
        "outputId": "ae60dc49-29e6-49ad-b795-2c878411193b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe based on the Year of Manufacture column\n",
            "Action: python_repl_ast\n",
            "Action Input: df[(df['Year of Manufacture'] >= 2000) & (df['Year of Manufacture'] <= 2006)]\u001b[0m\u001b[36;1m\u001b[1;3m          id    Car Brand                Car Model   Car Color  \\\n",
            "3        4.0         Audi                       A4      Orange   \n",
            "5        6.0      Bentley  Continental Flying Spur      Fuscia   \n",
            "6        7.0  Lamborghini                 Gallardo      Violet   \n",
            "12      13.0      Hyundai                  Elantra         Red   \n",
            "30      31.0   Volkswagen               New Beetle      Purple   \n",
            "...      ...          ...                      ...         ...   \n",
            "9978  9979.0        Dodge                  Caravan  Aquamarine   \n",
            "9991  9992.0        Honda                     CR-V        Teal   \n",
            "9993  9994.0          GMC                    Yukon      Purple   \n",
            "9994  9995.0         Ford                  Contour     Crimson   \n",
            "9995  9996.0   Land Rover               Freelander      Indigo   \n",
            "\n",
            "      Year of Manufacture  \n",
            "3                  2005.0  \n",
            "5                  2006.0  \n",
            "6                  2004.0  \n",
            "12                 2000.0  \n",
            "30                 2001.0  \n",
            "...                   ...  \n",
            "9978               2000.0  \n",
            "9991               2004.0  \n",
            "9993               2000.0  \n",
            "9994               2000.0  \n",
            "9995               2001.0  \n",
            "\n",
            "[2825 rows x 5 columns]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: df[(df['Year of Manufacture'] >= 2000) & (df['Year of Manufacture'] <= 2006)]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"df[(df['Year of Manufacture'] >= 2000) & (df['Year of Manufacture'] <= 2006)]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example of Command Interpretation using TensorFlow, and PyTorch"
      ],
      "metadata": {
        "id": "Fx89UmwyKPvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize commands\n",
        "tokenizer = Tokenizer()\n",
        "sample_commands = [\n",
        "    \"Get me all Toyota cars with color red\",\n",
        "    \"Get all Honda Civic\",\n",
        "    \"Get all cars that were manufactured between 2000 and 2006\"\n",
        "]\n",
        "tokenizer.fit_on_texts(sample_commands)\n",
        "sequences = tokenizer.texts_to_sequences(sample_commands)\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Define the TensorFlow model\n",
        "class CommandParserModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super(CommandParserModel, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, states=None, return_state=False):\n",
        "        x = self.embedding(x)\n",
        "        if states is None:\n",
        "            states = self.rnn.get_initial_state(x)\n",
        "        x, state_h, state_c = self.rnn(x, initial_state=states)\n",
        "        x = self.dense(x)\n",
        "        if return_state:\n",
        "            return x, (state_h, state_c)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "# Create the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 64\n",
        "rnn_units = 128\n",
        "tf_model = CommandParserModel(vocab_size, embedding_dim, rnn_units)\n",
        "\n",
        "# Example inference\n",
        "example_input = tf.constant(padded_sequences)\n",
        "predictions = tf_model(example_input)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "r3vMC01ZKeqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CommandDataset(Dataset):\n",
        "    def __init__(self, commands, tokenizer):\n",
        "        self.commands = commands\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sequences = tokenizer.texts_to_sequences(commands)\n",
        "        self.padded_sequences = pad_sequences(self.sequences, padding='post')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.commands)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.padded_sequences[idx], dtype=torch.long)\n",
        "\n",
        "# Define the PyTorch model\n",
        "class CommandParser(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(CommandParser, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Create the dataset and DataLoader\n",
        "command_dataset = CommandDataset(sample_commands, tokenizer)\n",
        "command_loader = DataLoader(command_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Create the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "output_dim = vocab_size\n",
        "torch_model = CommandParser(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Example inference\n",
        "for batch in command_loader:\n",
        "    output = torch_model(batch)\n",
        "    print(output)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "cZsk1ZObLM9f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}